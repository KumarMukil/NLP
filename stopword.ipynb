{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342e8a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c62844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb667dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f3b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing stop words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525ad020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'Intelligence', 'is', 'transforming', 'the', 'world', 'in', 'remarkable', 'ways', ',', 'from', 'enhancing', 'medical', 'diagnostics', 'to', 'powering', 'self-driving', 'cars', 'and', 'intelligent', 'assistants', '.']\n",
      "['Artificial', 'Intelligence', 'transforming', 'world', 'remarkable', 'ways', ',', 'enhancing', 'medical', 'diagnostics', 'powering', 'self-driving', 'cars', 'intelligent', 'assistants', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"\"\"Artificial Intelligence is transforming the world \n",
    "                  in remarkable ways, from enhancing medical diagnostics \n",
    "                  to powering self-driving cars and intelligent assistants.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "# they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "# with no lower case conversion\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6521029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom stopwords code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426d2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom stopwords removed:\n",
      "['artificial', 'refers', 'to', 'the', 'simulation', 'of', 'human', 'in', 'that', 'are', 'programmed', 'to', 'think', 'like', 'and', 'mimic', 'their', 'actions', 'ai', 'is', 'continuously', 'evolving', 'to', 'benefit', 'many', 'different', 'including', 'healthcare', 'finance', 'education', 'and', 'transportation']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Artificial Intelligence refers to the simulation of human intelligence in machines that are \n",
    "programmed to think like humans and mimic their actions. AI is continuously evolving to benefit \n",
    "many different industries, including healthcare, finance, education, and transportation.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "custom_stopwords = {\"machines\", \"intelligence\", \"humans\", \"industries\"}\n",
    "filtered_custom = [word for word in tokens if word not in custom_stopwords and word.isalnum()]\n",
    "\n",
    "print(\"Custom stopwords removed:\")\n",
    "print(filtered_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab168b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical stopwords removed:\n",
      "['in', 'over', 'systems', 'were', 'deployed', 'across', 'sector', 'for', 'data', 'analysis', 'and']\n"
     ]
    }
   ],
   "source": [
    "text = \"In 2025, over 3000 AI-driven systems were deployed across sector 9 for data analysis and decision-making.\"\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "numerical_stopwords = {token for token in tokens if token.isdigit()}\n",
    "filtered_numerical = [word for word in tokens if word not in numerical_stopwords and word.isalnum()]\n",
    "\n",
    "print(\"Numerical stopwords removed:\")\n",
    "print(filtered_numerical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "768e6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single character stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826b25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-character stopwords removed:\n",
      "['believe', 'ai', 'is', 'transformative', 'force', 'in', 'the', '21st', 'century', 'it', 'plays', 'key', 'role', 'in', 'domains', 'such', 'as', 'healthcare', 'where', 'single', 'diagnosis', 'can', 'save', 'lives', 'and', 'in', 'education', 'where', 'see', 'its', 'potential', 'to', 'enhance', 'learning']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"I believe AI is a transformative force in the 21st century. It plays a key role in domains such as \n",
    "healthcare, where a single diagnosis can save lives, and in education, where I see its potential to enhance learning.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "single_char_stopwords = {token for token in tokens if len(token) == 1 and token.isalpha()}\n",
    "filtered_single_char = [word for word in tokens if word not in single_char_stopwords and word.isalnum()]\n",
    "\n",
    "print(\"Single-character stopwords removed:\")\n",
    "print(filtered_single_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9491b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Contextual Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47855f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual stopwords removed (context-dependent):\n",
      "['artificial', 'intelligence', 'shape', 'the', 'future', 'in', 'ways', 'we', 'can', 't', 'yet', 'fully', 'predict', 'while', 'some', 'believe', 'ai', 'solve', 'major', 'global', 'problems', 'others', 'are', 'concerned', 'about', 'how', 'it', 'impact', 'employment', 'and', 'ethics', 'in', 'society']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Artificial Intelligence will shape the future in ways we canâ€™t yet fully predict. \n",
    "While some believe AI will solve major global problems, others are concerned about how it \n",
    "will impact employment and ethics in society.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "# In this context, we decide to filter out the future-intent word \"will\"\n",
    "contextual_stopwords = {\"will\"}\n",
    "filtered_contextual = [word for word in tokens if word not in contextual_stopwords and word.isalnum()]\n",
    "\n",
    "print(\"Contextual stopwords removed (context-dependent):\")\n",
    "print(filtered_contextual)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
